{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "### What is pandas?\n",
    "- A python package for data manipulation and analysis\n",
    "- Simplifies common tasks\n",
    "- Fast and efficient for large datasets\n",
    "\n",
    "### Basic functionality\n",
    "- Load data from various types of files\n",
    "- Filter, sort, edit and process data\n",
    "- Join and aggregate datasets\n",
    "- Display data in tables and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from a .csv file\n",
    "# This creates a pandas DataFrame object\n",
    "df = pd.read_csv('data/patient_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting an overview of the data\n",
    "\n",
    "Data is stored in **rows**, labelled by **indices**, and **columns**.\n",
    "\n",
    "- `df.head(n)` shows the first `n` rows (by default, `n` = 5)\n",
    "- `df.sample(n)` shows a random sample of `n` rows\n",
    "- `df.tail(n)` shows the last `n` rows\n",
    "\n",
    "Some other useful commands:\n",
    "- `df.shape`: number of rows and columns\n",
    "- `df.columns`: list of columns\n",
    "- `df.dtypes`: show data types of each column (note: strings are called \"objects\" in pandas)\n",
    "- `df.info()`: show the number of non-null entries and data types in each column\n",
    "- `df.describe()`: make DataFrame of statistical info about each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 8 entries\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of entries and data type of each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics for each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of rows and columns\n",
    "rows, cols = df.shape\n",
    "print(rows, 'rows and', cols, 'columns') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data entries\n",
    "\n",
    "- Each entry has a corresponding **row** (labelled by an **index**) and **column** (labelled by a **column header**).\n",
    "- The rows and columnss can also be accessed by an integer based on their positions.\n",
    "- Hence there are 2 ways to access a data entry (known as \"**indexing**\"):\n",
    "    - by **position**\n",
    "    - by **label**\n",
    "    \n",
    "### Position-based indexing (`iloc`)\n",
    "- Use `iloc` with square brackets to access data at a specific position, e.g. `df.iloc[2, 7]`\n",
    "- The order is [row, column]\n",
    "- Can also access a range of values with `:`, e.g. `df.iloc[10:20, 7:9]`\n",
    "- If only one value is given in the square brackets, all columns will be returned\n",
    "- Note: this is very similar to indexing numpy arrays (and in fact, pandas is built on top of numpy)\n",
    "\n",
    "### Label-based indexing (`loc`)\n",
    "- Use `loc` with square brackets to access data in rows and columns with specific labels, e.g. `df.loc[:10, 'age']`\n",
    "- Note that by default, the row labels are the same as the row indices - but this doesn't always have to be the case!\n",
    "- Access multiple labels at once using a list, e.g. `df.loc[:10, ['patient', 'age', 'sex']]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataframe](dataframe.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a single entry\n",
    "df.iloc[2, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a range of entries\n",
    "df.iloc[10:20, 7:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns for rows 0-10\n",
    "df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a single column and multiple rows\n",
    "df.loc[:10, 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access multiple columns and rows\n",
    "# Note, the return value for .loc() and .iloc() is another DataFrame!\n",
    "df_small = df.loc[:10, ['patient', 'age', 'sex']]\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing can also be used to change values inside the DataFrame\n",
    "- Note: this will permanently modify the DataFrame\n",
    "- A useful function is `df.copy()` so we don't overwrite our original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy and change some values\n",
    "df_small2 = df_small.copy()\n",
    "df_small2.loc[2, 'sex'] = 'F'\n",
    "df_small2.loc[4, 'age'] = 10000\n",
    "display(df_small2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns (taking a \"slice\" of the DataFrame)\n",
    "- If we just want to select certain columns but keep every row, we don't need to use `iloc`/`loc`.\n",
    "- To take a single column from the DataFrame, use square brackets directly after the DataFrame variable, e.g. `df['age']`\n",
    "- To take multiple columns, use a list inside square brackets (i.e. two layers of brackets), e.g. `df[['patient', 'age', 'sex']]`\n",
    "- Beware that the slice is just a **view** of the existing data, not a **copy**; if you try to modify the slice you'll get a warning.\n",
    "- To take a slice of the DataFrame and make a brand new object, use the `.copy()` method, e.g. `df_new = df[['patient', 'age', 'sex']].copy()`\n",
    "\n",
    "### Deleting columns\n",
    "- We can also **remove** certain columns with the `drop` function.\n",
    "- Do this using: `df_new = df.drop(['age', 'sex'], axis=1)`.\n",
    "- The `axis=1` is important: if we set `axis=0`, we would drop **rows** instead (this is the case for a lot of pandas DataFrame functions).\n",
    "- Also important: this function doesn't modify the **original** DataFrame, but instead returns a **new** DataFrame with the chosen columns removed.\n",
    "- If we wanted to modify the original, could run: `df.drop(['age', 'sex'], axis=1, inplace=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single column\n",
    "display(df['age'].head())\n",
    "\n",
    "# Get multiple columns\n",
    "display(df[['age', 'sex', 'patient']].head())  # Note, we can specify columns in any order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DataFrame with subset of columns\n",
    "df2 = df[['patient', 'age', 'sex', 'cohort']].copy()  # Use .copy to ensure that df2 is a new DataFrame\n",
    "display(df2.head())\n",
    "\n",
    "# Create new DataFrame with 'age' column dropped\n",
    "df3 = df2.drop('age', axis=1)\n",
    "display(df3.head())\n",
    "\n",
    "# We can also modify the original DataFrame with the \"inplace\" parameter\n",
    "df2.drop(['sex', 'cohort'], axis=1, inplace=True)\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we try to modify a slice without making a copy, we'll get a warning...\n",
    "df_slice = df[['patient', 'age']]\n",
    "df_slice['age'] *= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the row label\n",
    "- I mentioned earlier that row labels aren't necessarily the same as row indices.\n",
    "- The row labels can be set when data is loaded, or set later from the values in a column using `df.set_index`.\n",
    "- Like `drop`, this function makes a **new** DataFrame unless `inplace=True` is used.\n",
    "- Sometimes it's useful to set `drop=False` so that the chosen column stays in the DataFrame.\n",
    "- You can relabel your indices with numbers using `df.reset_index()`. Use `df.reset_index(drop=True)` if you don't want to save the original indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DataFrame with \"patient\" as the index\n",
    "df2 = df.set_index('patient', drop=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataSeries objects\n",
    "- You might be wondering why the output looks different when we display a single column of data vs. multiple columns...\n",
    "- That's because multiple columns make up a **DataFrame**, whereas each individual column is a **DataSeries**.\n",
    "- A DataSeries is just a list of values, each with a row label.\n",
    "\n",
    "#### Useful functions for DataSeries:\n",
    "- `count()`: count non-null entries.\n",
    "- `sum()`: add up entries.\n",
    "- `mean()`: calculate the mean.\n",
    "- `value_counts()`: show how many of each value is in the series.\n",
    "- `nunique()`: count unique values.\n",
    "- `unique()`: return an array of the unique values in the series.\n",
    "- `to_list()`: convert the series to a python list.\n",
    "- `notna()` / `isna()`: get only non-NaN/NaN entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataframe](dataframe-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a DataSeries containing patient ages\n",
    "ages = df['age']\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use some of the DataSeries functions\n",
    "print('Number of entries:', ages.count())\n",
    "print('Sum of entries:', ages.sum())\n",
    "print('Mean age:', ages.mean())\n",
    "print('Number of unique entries:', ages.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataSeries of patient sex\n",
    "sexes = df['sex']\n",
    "\n",
    "# Show value counts\n",
    "sexes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get array of unique sexes\n",
    "unique_sexes = sexes.unique()\n",
    "unique_sexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data with masks\n",
    "- Applying a boolean condition to a DataSeries (such as a column of our DataFrame) will produce a new DataSeries of booleans.\n",
    "- This DataSeries can be used as a **\"mask\"** to filter out data from a DataSeries or DataFrame. To do this, put the mask in square brackets, e.g. `df_masked = df[mask]`.\n",
    "- Rows in the **masked** DataFrame will keep their labels from the original - this is useful if we want to refer back to the original DataFrame. \n",
    "- Multiple masks can be used in combination using single `&` (and) or `|` (or) operators.\n",
    "- Masks can be inverted using `~`, e.g. `df[~mask]`.\n",
    "- Any boolean column can also be used as a mask.\n",
    "- The DataSeries functions `isna()` and `notna()` are useful for masking NaN values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mask for female patients only\n",
    "mask_f = df['sex'] == 'F'\n",
    "display(mask_f.head())\n",
    "mask_f.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mask to the DataFrame\n",
    "print('Original DataFrame shape:', df.shape)\n",
    "df_female = df[mask_f]\n",
    "print('New DataFrame shape:', df_female.shape)\n",
    "\n",
    "df_female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for age, sex, and cohort\n",
    "mask_age = df['age'] < 65\n",
    "mask_cohort = df['cohort'] == 'C'\n",
    "df_masked = df[mask_f & mask_age & mask_cohort]\n",
    "df_masked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index the new DataFrame\n",
    "df_masked.reset_index(inplace=True, drop=True)\n",
    "df_masked.head()  # Note: the original index gets saved as a column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have columns that already containing booleans, you can use them as masks!\n",
    "# E.g. get subset of patients with no baseline data\n",
    "df_no_baseline = df[~df['has_baseline']]  # Remember, ~ to invert mask\n",
    "df_no_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask out rows with a NaN value in a given column\n",
    "df_no_nan_alcohol = df[df['alcohol_metric'].notna()]\n",
    "df_no_nan_alcohol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data\n",
    "- Columns can be combined using mathematical operations in the same way as numpy arrays.\n",
    "- The output of an operation on columns can be assigned to a new column, e.g. `df['age_sq'] = df['age'] ** 2`.\n",
    "\n",
    "#### Dealing with NaN values:\n",
    "- `fillna(value)`: replace all NaN entries with some value.\n",
    "- `dropna()`: drop any rows containing NaN entries. Can also be used as `dropna(column_name)` to only drop NaN in a specific column.\n",
    "\n",
    "#### Adjusting data types:\n",
    "- `df[col_name].astype(type)`: cast data in a column to a difference type.\n",
    "- `pd.to_datetime(df[col_name])`: convert a column datatype to `datetime`\n",
    "- `pd.to_timedelta(df[col_name])`: convert a column datatype to `timedelta`\n",
    "\n",
    "#### Other useful functions:\n",
    "- `sort_values(by=column_name, ascending=True/False)`: sort DataFrame based on values in a column.\n",
    "- `apply(func, axis=1)`: apply a function to every row.\n",
    "- `apply(func)` when used on a DataSeries: apply function to every element in the series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical operations\n",
    "df2 = df[['patient', 'smoking_metric', 'alcohol_metric']].copy()\n",
    "df2['smoking_and_alcohol'] = df2['smoking_metric'] + 2 * df2['alcohol_metric']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in NaN values\n",
    "df2 = df[['patient', 'alcohol_metric']].copy()\n",
    "display(df2.tail())\n",
    "df2.fillna(0, inplace=True)\n",
    "display(df2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN entries\n",
    "df2 = df[['patient', 'alcohol_metric']].copy()\n",
    "df2.dropna(inplace=True)\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using astype to round integers\n",
    "df2 = df[['patient', 'age', 'sex']].copy()\n",
    "df2['age'] = df2['age'].astype(int)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dates to datetime objects\n",
    "df['treatment_end'] # At this point, the date is just a string (referred to as an \"object\" in pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date string to a datetime object\n",
    "df['treatment_end'] = pd.to_datetime(df['treatment_end'])\n",
    "df['treatment_end']  # Now the dtype is datetime64!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date\n",
    "df_sorted = df.sort_values(by='treatment_end', ascending=False)\n",
    "df_sorted[['patient', 'treatment_end']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a function to a single column\n",
    "def get_age_description(age):\n",
    "    if age < 50:\n",
    "        return 'young'\n",
    "    elif age < 60:\n",
    "        return 'middle-aged'\n",
    "    else:\n",
    "        return 'old'\n",
    "\n",
    "df2 = df[['patient', 'age']].copy()\n",
    "df2['age_desc'] = df2['age'].apply(get_age_description)  # We are applying this to a single column\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a function to each row\n",
    "def description(row):\n",
    "    age = int(row['age'])\n",
    "    sex = row['sex']\n",
    "    person = 'man' if sex == 'M' else 'woman'\n",
    "    return f'{age}-year-old {person}'\n",
    "\n",
    "df2 = df[['patient', 'age', 'sex']].copy()\n",
    "df2['desc'] = df2.apply(description, axis=1)  # We are applying to the whole DataFrame, so we need to \n",
    "                                              # specify axis=1 (i.e. loop over rows, not columns)\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying with a lambda function\n",
    "# Sometimes, you want to quickly apply a one-line method to a column, e.g. converting a string to lowercase:\n",
    "df2['sex'] = df2['sex'].apply(lambda x: x.lower())\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Pandas DataFrames can be loaded from many different inputs:\n",
    "- `.csv`: use `pd.read_csv(filename)`.\n",
    "- Excel spreadsheets: use `pd.read_excel(filename)`.\n",
    "- Can also create a DataFrame from a list of dictionaries.\n",
    "\n",
    "DataFrames can be easily written to a csv file using `df.to_csv(filename).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading from excel\n",
    "df = pd.read_excel('../../../Toxicity/data/case_detail.xlsx')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to tidy it up a bit!\n",
    "# Drop empty first row\n",
    "df.drop(0, inplace=True)  # Don't forget to set inplace=True to modify the original DataFrame\n",
    "\n",
    "# Drop empty last column\n",
    "df.drop(df.columns[-1], axis=1, inplace=True)  # df.columns is useful for getting a list of column names!\n",
    "                                               # Don't forget to specify axis=1 to drop a column\n",
    "\n",
    "# Rename columns\n",
    "df.rename({'Age': 'age', \n",
    "           'cons or disc?': 'cohort',\n",
    "           'HEP ID': 'patient'}, axis=1, inplace=True)\n",
    "\n",
    "# Take only the columns we care about\n",
    "to_keep = ['patient', 'cohort', 'age', 'primary site', 'SACT', 'max dose']\n",
    "df = df[to_keep]\n",
    "\n",
    "# Convert max dose to an integer\n",
    "import numpy as np\n",
    "def dose_to_int(dose_str):\n",
    "    dose = str(dose_str).split('G')[0]\n",
    "    dose = dose.strip()\n",
    "    try:\n",
    "        return int(dose)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "df['max dose'] = df['max dose'].apply(dose_to_int)\n",
    "\n",
    "# Drop entries with NaN max dose using a mask\n",
    "dose_notna_mask = df['max dose'].notna()\n",
    "df = df[dose_notna_mask]\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from python dictionaries\n",
    "# Create a list of rows, with column names as keys:\n",
    "rows = [\n",
    "    {\"name\": \"Bob\", \"age\": 50, \"sex\": \"M\", \"employed\": True, \"children\": 3},\n",
    "    {\"name\": \"Alice\", \"age\": 46, \"sex\": \"F\", \"employed\": False, \"favourite colour\": \"red\"}\n",
    "]\n",
    "df = pd.DataFrame(rows)\n",
    "df  # Note: any missing entries are filled in as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing out data\n",
    "df.to_csv(\"data/my_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this writes the index to the file as well, which will then be read in as a column when you reload...\n",
    "df2 = pd.read_csv(\"data/my_data.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: set index=False when writing\n",
    "df.to_csv(\"data/my_data.csv\", index=False)\n",
    "df2 = pd.read_csv(\"data/my_data.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use the first column as the index when reading in\n",
    "df.to_csv(\"data/my_data.csv\", index=True)\n",
    "df2 = pd.read_csv(\"data/my_data.csv\", index_col=0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames\n",
    "- Concatenate two DataFrames (i.e. stack their rows together): `df = pd.concat([df1, df2])`\n",
    "- Merge two DataFrames based on a column value using `df_merged = df1.merge(df2, on=col_name)`\n",
    "- Add extra rows to a DataFrame using `df.append(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. if we wanted to combine two patient cohorts (i.e. add extra rows)\n",
    "df = pd.read_csv(\"data/patient_info.csv\")\n",
    "display(df.head())\n",
    "df_consolidation = df[df['cohort'] == 'C'].reset_index(drop=True)\n",
    "df_discovery = df[df['cohort'] == 'D'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together the discovery and consolidation cohorts\n",
    "df_all = pd.concat([df_consolidation, df_discovery])\n",
    "\n",
    "# Reset indices\n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also append a single line using a dictionary\n",
    "df_plus = df_all.append({'patient': \"TEST\", \"age\": 20, \"has_dose\": True}, ignore_index=True)\n",
    "df_plus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two DataFrames containing the same patients but different columns\n",
    "# Load two DataFrames containing patient info\n",
    "df_info = pd.read_csv('data/patient_info.csv')\n",
    "df_late = pd.read_csv('data/late_6_months.csv')\n",
    "\n",
    "# Merge on patient ID\n",
    "df = df_info.merge(df_late, on='patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting data\n",
    "Pandas conveniently has a built-in plotting method! This is built on top of matplotlib.\n",
    "\n",
    "- Scatter plot: `df.plot(x=x_col, y=y_col, kind=\"scatter\")`\n",
    "- Histogram: `df[col_name].plot(kind=\"hist\")` or, even shorter, `df[col_name].hist()`\n",
    "- Bar chart: `df[col_name].value_counts().plot(kind=\"bar\")`\n",
    "- Pie chart: `df[col_name].value_counts().plot(kind=\"pie\")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "df = pd.read_csv(\"data/patient_info.csv\")\n",
    "ax = df.plot(x='age', y='mass', kind='scatter', figsize=(10, 5))  # Capture the output as a matplotlib axis\n",
    "\n",
    "# Adjust properties of ax\n",
    "ax.set_title(\"Age vs. patient weight\")\n",
    "\n",
    "# Save figure using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.savefig(\"data/my_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "df['age'].plot(kind=\"hist\", bins=8, title=\"Patient age\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart/pie chart\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "df[\"sex\"].value_counts().plot(kind=\"bar\", title=\"Patient sex\", ax=ax[0]);  # Note: you can specify the axis to use\n",
    "df[\"sex\"].value_counts().plot(kind=\"pie\", ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: plotting with seaborn\n",
    "Seaborn is a python package with a lot of nice built-in plotting functionality that works out-of-the-box with pandas. Some examples:\n",
    "\n",
    "- `lmplot(x=x_col, y=y_col, data=df)`: scatter plot with linear regression fit.\n",
    "- `pairplot(df)`: grid of scatter plots of all columns (note: you might want to reduce your columns a bit, or this will be very slow!)\n",
    "- `heatmap(df.corr())`: heatmap of correlations between columns.\n",
    "- `histplot(data=df, x=x_col, hue=col_to_hue)`: histogram of a column. If a \"hue\" variable is set, multiple histograms will be plotted based on the column given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seaborn linear regression plot\n",
    "import seaborn as sns\n",
    "sns.lmplot(x='age', y='smoking_metric', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn pair plot\n",
    "df_reduced = df[['age', 'sex', 'smoking_metric', 'mass', 'alcohol_metric']]\n",
    "sns.pairplot(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn correlation heatmap\n",
    "sns.heatmap(df_reduced.corr(), cmap=\"RdBu\")\n",
    "\n",
    "# Note: we can also extract the numerical correlation matrix using:\n",
    "correlation = df_reduced.corr()\n",
    "display(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.histplot(data=df, x=\"mass\", hue=\"sex\", kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lmplot with hue\n",
    "sns.lmplot(data=df, x=\"age\", y=\"mass\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data\n",
    "Sometimes you might want to group data into subsets based on the value of a column, and then perform an operation on each subset.\n",
    "\n",
    "Generally when doing this, your workflow should follow the **split-apply-combine** routine:\n",
    "   1. Split a DataFrame into groups\n",
    "   2. Apply some operation to the data in each group\n",
    "   3. Combine the results into a new DataFrame\n",
    "\n",
    "- To make a group, use the `groupby()` method; e.g. to group by patient ID: `groups = df.groupby(\"patient\")`.\n",
    "- This produces a special DataFrameGroupBy object.\n",
    "- You can then apply operations such as `sum`, `mean`, `min`, `max` etc to all groups at once, e.g. `groups[\"mass\"].mean()` would return a DataSeries containing the mean mass of each patient.\n",
    "- You can also apply an operation to multiple columns at once; this gives you a DataFrame, e.g. `groups[[col1, col2]].max()` would give you a DataFrame containing the maxima of `col2` and `col2` in each group.\n",
    "- To get an individual group as a DataFrame, use `groups.get_group(group_name)`, where `group_name` is the value of that group in the column you used for grouping.\n",
    "- You can also group by multiple columns at once: `groups = df.groupby((col1, col2))`.\n",
    "- To apply multiple operations at once, use the `agg` method, e.g. to get the mean, min, and max mass of each patient: `groups[\"mass\"].agg([\"mean\", \"min\", \"max\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>disease</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>mass</th>\n",
       "      <th>ear_pain</th>\n",
       "      <th>external_ear_inflammation</th>\n",
       "      <th>hearing_impaired</th>\n",
       "      <th>tinnitus</th>\n",
       "      <th>cataract</th>\n",
       "      <th>...</th>\n",
       "      <th>CTCAE_sdi</th>\n",
       "      <th>CTCAE_sdi_grade</th>\n",
       "      <th>CTCAE_dysphagia</th>\n",
       "      <th>CTCAE_dysphagia_grade</th>\n",
       "      <th>EORTC_dry_mouth</th>\n",
       "      <th>EORTC_dry_mouth_grade</th>\n",
       "      <th>EORTC_sticky_saliva</th>\n",
       "      <th>EORTC_sticky_saliva_grade</th>\n",
       "      <th>EORTC_taste</th>\n",
       "      <th>EORTC_taste_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VT1_H_00BE02K1</td>\n",
       "      <td>head_and_neck</td>\n",
       "      <td>late</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VT1_H_01DE91K1</td>\n",
       "      <td>head_and_neck</td>\n",
       "      <td>late</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VT1_H_01DE91K1</td>\n",
       "      <td>head_and_neck</td>\n",
       "      <td>late</td>\n",
       "      <td>2014-07-16</td>\n",
       "      <td>87.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VT1_H_01DE91K1</td>\n",
       "      <td>head_and_neck</td>\n",
       "      <td>late</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VT1_H_01DE91K1</td>\n",
       "      <td>head_and_neck</td>\n",
       "      <td>late</td>\n",
       "      <td>2016-07-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          patient        disease stage        date  mass  ear_pain  \\\n",
       "0  VT1_H_00BE02K1  head_and_neck  late  2014-11-05  50.0       0.0   \n",
       "1  VT1_H_01DE91K1  head_and_neck  late  2014-03-26  83.0       0.0   \n",
       "2  VT1_H_01DE91K1  head_and_neck  late  2014-07-16  87.7       0.0   \n",
       "3  VT1_H_01DE91K1  head_and_neck  late  2015-07-28   NaN       0.0   \n",
       "4  VT1_H_01DE91K1  head_and_neck  late  2016-07-29   NaN       0.0   \n",
       "\n",
       "   external_ear_inflammation  hearing_impaired  tinnitus  cataract  ...  \\\n",
       "0                        0.0               0.0       0.0       0.0  ...   \n",
       "1                        0.0               0.0       0.0       0.0  ...   \n",
       "2                        0.0               0.0       0.0       0.0  ...   \n",
       "3                        0.0               0.0       0.0       0.0  ...   \n",
       "4                        0.0               0.0       0.0       0.0  ...   \n",
       "\n",
       "   CTCAE_sdi  CTCAE_sdi_grade  CTCAE_dysphagia  CTCAE_dysphagia_grade  \\\n",
       "0          0              0.0                1                    4.0   \n",
       "1          1              2.0                0                    0.0   \n",
       "2          1              2.0                0                    0.0   \n",
       "3          1              2.0                0                    0.0   \n",
       "4          1              2.0                0                    0.0   \n",
       "\n",
       "   EORTC_dry_mouth  EORTC_dry_mouth_grade  EORTC_sticky_saliva  \\\n",
       "0                1                    3.0                    1   \n",
       "1                0                    1.0                    0   \n",
       "2                0                    1.0                    0   \n",
       "3                0                    1.0                    0   \n",
       "4                0                    1.0                    0   \n",
       "\n",
       "   EORTC_sticky_saliva_grade  EORTC_taste  EORTC_taste_grade  \n",
       "0                        4.0            0                1.0  \n",
       "1                        1.0            1                4.0  \n",
       "2                        1.0            1                4.0  \n",
       "3                        1.0            1                4.0  \n",
       "4                        1.0            1                4.0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataset with multiple entries per patient\n",
    "df = pd.read_csv('data/late_all.csv', index_col=0).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by patient ID\n",
    "groups = df.groupby('patient')\n",
    "type(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTCAE_dysphagia_grade</th>\n",
       "      <th>EORTC_dry_mouth_grade</th>\n",
       "      <th>EORTC_taste_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VT1_H_00BE02K1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_01DE91K1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_03F693K1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_042C02K1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_052D61K1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_F894CK1L</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_F8E46K1L</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FA43E1K1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FBD27K1L</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FDE391K1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                CTCAE_dysphagia_grade  EORTC_dry_mouth_grade  \\\n",
       "patient                                                        \n",
       "VT1_H_00BE02K1                    4.0                    3.0   \n",
       "VT1_H_01DE91K1                    0.0                    1.0   \n",
       "VT1_H_03F693K1                    3.0                    4.0   \n",
       "VT1_H_042C02K1                    2.0                    4.0   \n",
       "VT1_H_052D61K1                    0.0                    2.0   \n",
       "...                               ...                    ...   \n",
       "VT1_H_F894CK1L                    3.0                    3.0   \n",
       "VT1_H_F8E46K1L                    2.0                    2.0   \n",
       "VT1_H_FA43E1K1                    0.0                    3.0   \n",
       "VT1_H_FBD27K1L                    1.0                    3.0   \n",
       "VT1_H_FDE391K1                    0.0                    2.0   \n",
       "\n",
       "                EORTC_taste_grade  \n",
       "patient                            \n",
       "VT1_H_00BE02K1                1.0  \n",
       "VT1_H_01DE91K1                4.0  \n",
       "VT1_H_03F693K1                4.0  \n",
       "VT1_H_042C02K1                2.0  \n",
       "VT1_H_052D61K1                2.0  \n",
       "...                           ...  \n",
       "VT1_H_F894CK1L                3.0  \n",
       "VT1_H_F8E46K1L                2.0  \n",
       "VT1_H_FA43E1K1                2.0  \n",
       "VT1_H_FBD27K1L                2.0  \n",
       "VT1_H_FDE391K1                3.0  \n",
       "\n",
       "[294 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get maximum value of various toxicity scores for each patient\n",
    "groups[['CTCAE_dysphagia_grade', 'EORTC_dry_mouth_grade', 'EORTC_taste_grade']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VT1_H_00BE02K1</th>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_01DE91K1</th>\n",
       "      <td>2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>87.7</td>\n",
       "      <td>85.35</td>\n",
       "      <td>3.323402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_03F693K1</th>\n",
       "      <td>4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.80</td>\n",
       "      <td>3.452535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_042C02K1</th>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>46.10</td>\n",
       "      <td>4.138840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_052D61K1</th>\n",
       "      <td>3</td>\n",
       "      <td>135.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_F894CK1L</th>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.50</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_F8E46K1L</th>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FA43E1K1</th>\n",
       "      <td>3</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>68.50</td>\n",
       "      <td>1.322876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FBD27K1L</th>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.75</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FDE391K1</th>\n",
       "      <td>1</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                count    min    max    mean       std\n",
       "patient                                              \n",
       "VT1_H_00BE02K1      1   50.0   50.0   50.00       NaN\n",
       "VT1_H_01DE91K1      2   83.0   87.7   85.35  3.323402\n",
       "VT1_H_03F693K1      4   54.0   61.6   56.80  3.452535\n",
       "VT1_H_042C02K1      3   43.0   50.8   46.10  4.138840\n",
       "VT1_H_052D61K1      3  135.0  145.0  140.00  5.000000\n",
       "...               ...    ...    ...     ...       ...\n",
       "VT1_H_F894CK1L      2   42.0   43.0   42.50  0.707107\n",
       "VT1_H_F8E46K1L      2  120.0  120.0  120.00  0.000000\n",
       "VT1_H_FA43E1K1      3   67.5   70.0   68.50  1.322876\n",
       "VT1_H_FBD27K1L      4   70.0   73.0   71.75  1.500000\n",
       "VT1_H_FDE391K1      1   83.5   83.5   83.50       NaN\n",
       "\n",
       "[294 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use agg to get various properties of patient masses\n",
    "groups['mass'].agg(['count', 'min', 'max', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VT1_H_00BE02K1</th>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_01DE91K1</th>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>2018-06-13</td>\n",
       "      <td>1540 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_03F693K1</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>636 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_042C02K1</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>273 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_052D61K1</th>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>996 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_F894CK1L</th>\n",
       "      <td>2015-11-19</td>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>91 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_F8E46K1L</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>2017-02-22</td>\n",
       "      <td>413 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FA43E1K1</th>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>648 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FBD27K1L</th>\n",
       "      <td>2015-05-07</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>658 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT1_H_FDE391K1</th>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      min        max     range\n",
       "patient                                       \n",
       "VT1_H_00BE02K1 2014-11-05 2014-11-05    0 days\n",
       "VT1_H_01DE91K1 2014-03-26 2018-06-13 1540 days\n",
       "VT1_H_03F693K1 2017-05-11 2019-02-06  636 days\n",
       "VT1_H_042C02K1 2014-10-01 2015-07-01  273 days\n",
       "VT1_H_052D61K1 2015-06-22 2018-03-14  996 days\n",
       "...                   ...        ...       ...\n",
       "VT1_H_F894CK1L 2015-11-19 2016-02-18   91 days\n",
       "VT1_H_F8E46K1L 2016-01-06 2017-02-22  413 days\n",
       "VT1_H_FA43E1K1 2014-09-22 2016-07-01  648 days\n",
       "VT1_H_FBD27K1L 2015-05-07 2017-02-23  658 days\n",
       "VT1_H_FDE391K1 2014-07-17 2014-07-17    0 days\n",
       "\n",
       "[294 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use agg to get date range\n",
    "# First, convert \"date\" column into a datetime object\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Split-apply-recombine in one line:\n",
    "# 1. Split by patient ID\n",
    "# 2. Find min and max date for each group and combine into a new DataFrame\n",
    "df_dates = df.groupby('patient')['date'].agg(['min', 'max'])\n",
    "\n",
    "# Add new column containing the difference between min and max\n",
    "df_dates['range'] = df_dates['max'] - df_dates['min']\n",
    "df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
